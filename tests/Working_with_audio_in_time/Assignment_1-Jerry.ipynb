{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your working directory is: /Users/jer/Documents/Programming/Senior_Design/Deepcut/tests/Working_with_audio_in_time-Jerry\n",
      "This block will run force allignment with the command:\n",
      "montreal-forced-aligner/bin/mfa_align audio_transcripts librispeech-lexicon.txt English alligned --verbose\n",
      "audio_transcripts/US114_F60_TG_VSDRC031.wav\n",
      "int16\n",
      "audio_transcripts/US114_F60_TG_VSDRC025.wav\n",
      "int16\n",
      "audio_transcripts/US114_F60_TG_VSDRC019.wav\n",
      "int16\n",
      "audio_transcripts/US114_F60_TG_VSDRC018.wav\n",
      "int16\n",
      "audio_transcripts/US114_F60_TG_VSDRC024.wav\n",
      "int16\n",
      "audio_transcripts/US114_F60_TG_VSDRC030.wav\n",
      "int16\n",
      "audio_transcripts/US114_F60_TG_VSDRC026.wav\n",
      "int16\n",
      "audio_transcripts/US114_F60_TG_VSDRC032.wav\n",
      "int16\n",
      "audio_transcripts/US114_F60_TG_VSDRC033.wav\n",
      "int16\n",
      "audio_transcripts/US114_F60_TG_VSDRC027.wav\n",
      "int16\n",
      "audio_transcripts/US114_F60_TG_VSDRC023.wav\n",
      "int16\n",
      "audio_transcripts/US114_F60_TG_VSDRC022.wav\n",
      "int16\n",
      "audio_transcripts/US114_F60_TG_VSDRC008.wav\n",
      "int16\n",
      "audio_transcripts/US114_F60_TG_VSDRC034.wav\n",
      "int16\n",
      "audio_transcripts/US114_F60_TG_VSDRC020.wav\n",
      "int16\n",
      "audio_transcripts/US114_F60_TG_VSDRC021.wav\n",
      "int16\n",
      "audio_transcripts/US114_F60_TG_VSDRC035.wav\n",
      "int16\n",
      "audio_transcripts/US114_F60_TG_VSDRC009.wav\n",
      "int16\n",
      "audio_transcripts/US114_F60_TG_VSDRC010.wav\n",
      "int16\n",
      "audio_transcripts/US114_F60_TG_VSDRC004.wav\n",
      "int16\n",
      "audio_transcripts/US114_F60_TG_VSDRC005.wav\n",
      "int16\n",
      "audio_transcripts/US114_F60_TG_VSDRC011.wav\n",
      "int16\n",
      "audio_transcripts/US114_F60_TG_VSDRC007.wav\n",
      "int16\n",
      "audio_transcripts/US114_F60_TG_VSDRC013.wav\n",
      "int16\n",
      "audio_transcripts/US114_F60_TG_VSDRC012.wav\n",
      "int16\n",
      "audio_transcripts/US114_F60_TG_VSDRC006.wav\n",
      "int16\n",
      "audio_transcripts/US114_F60_TG_VSDRC002.wav\n",
      "int16\n",
      "audio_transcripts/US114_F60_TG_VSDRC016.wav\n",
      "int16\n",
      "audio_transcripts/US114_F60_TG_VSDRC017.wav\n",
      "int16\n",
      "audio_transcripts/US114_F60_TG_VSDRC003.wav\n",
      "int16\n",
      "audio_transcripts/US114_F60_TG_VSDRC029.wav\n",
      "int16\n",
      "audio_transcripts/US114_F60_TG_VSDRC015.wav\n",
      "int16\n",
      "audio_transcripts/US114_F60_TG_VSDRC001.wav\n",
      "int16\n",
      "audio_transcripts/US114_F60_TG_VSDRC000.wav\n",
      "int16\n",
      "audio_transcripts/US114_F60_TG_VSDRC014.wav\n",
      "int16\n",
      "audio_transcripts/US114_F60_TG_VSDRC028.wav\n",
      "int16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jer/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:47: WavFileWarning: Chunk (non-data) not understood, skipping it.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Partial solution to part 1. The folder stucture and files used are given.\n",
    "The concatenated audio (all.wav) as well as US114_F60_TG_VSDRC000.TextGrid is included as an example.\n",
    "Note that I am using a Mac to write this. Adjust accordingly\n",
    "'''\n",
    "\n",
    "from pathlib import Path\n",
    "from intervaltree import IntervalTree\n",
    "from textgrid import TextGrid\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io.wavfile as wav\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# I like to define my filepaths at the top of the program. Keeps it easy to adjust\n",
    "# I'm spacing out most of these lines for readability\n",
    "\n",
    "# Use the version for your OS\n",
    "mfa_path = Path('montreal-forced-aligner/bin/mfa_align') \n",
    "\n",
    "# i.e. input path. Just the directory containing our audio & transcripts\n",
    "corpus_path = Path('audio_transcripts/') \n",
    "\n",
    "# Defines the different words that exist in the transcripts and their phonemes\n",
    "dictionary_path = Path('librispeech-lexicon.txt')\n",
    "\n",
    "output_path = Path('alligned/')\n",
    "\n",
    "# Edit 2: I forgot to specify English as the acoustic_model_path argument. \n",
    "# Should work for all versions of MFA. Bit unintuitive\n",
    "cmd = '%s %s %s English %s --verbose' % (mfa_path, corpus_path, dictionary_path, output_path)\n",
    "\n",
    "print('Your working directory is: %s' % pathlib.Path().resolve())\n",
    "print('This block will run force allignment with the command:\\n%s' % cmd)\n",
    "# If it breaks here: \n",
    "# Run \"cd your_working_directory\" followed by the listed command in your command prompt. \n",
    "# os.system(cmd) \n",
    "\n",
    "# Get list of paths because Pathlib's glob is a generator\n",
    "corpus_audio = [path for path in corpus_path.glob('*.wav')] \n",
    "output_path = Path('all.wav') \n",
    "\n",
    "pad_time = 3 # seconds\n",
    "all_padded = [] # list that stores padded audio data before concatenation\n",
    "for file in corpus_audio:\n",
    "    sample_rate, data = wav.read(file)\n",
    "    \n",
    "    # The concatenated data (even zeros) should be the same data type\n",
    "    padding = np.zeros(pad_time * sample_rate).astype(data.dtype)\n",
    "    \n",
    "    # Note that np.concatenate takes a tuple or a list as the first argument. \n",
    "    # The following is missing parentheses: np.concatenate(data, padding, axis=0) \n",
    "    padded = np.concatenate((data, padding), axis=0) \n",
    "    \n",
    "    # Concatenate data and padding and add to end of list\n",
    "    all_padded.append(padded)\n",
    "\n",
    "    \n",
    "# ###############################################\n",
    "# # Concatenate all_padded and write as all.wav \n",
    "# ###############################################\n",
    "# concat = np.\n",
    "# wav.write(output_path, rate, concat) # ***\n",
    "        \n",
    "\n",
    "# trees = []\n",
    "# for file in corpus_path.glob('*.TextGrid'):\n",
    "#     tree = IntervalTree()\n",
    "#     ###############################################\n",
    "#     # Determine how to index through textgrid intervals \n",
    "#     # Add each interval to tree (use tree.addi)\n",
    "#     ###############################################\n",
    "#     intervals = # Read .textgrid file\n",
    "#     for interval in intervals:\n",
    "#         tree.addi()\n",
    "\n",
    "\n",
    "# # Time axis will be given by\n",
    "# t = np.linspace(0, len(concat)/rate, num = len(concat))\n",
    "# ##################\n",
    "# # Plot t vs data\n",
    "# ##################\n",
    "        \n",
    "        \n",
    "        \n",
    "# ###############################################\n",
    "# # Shift each interval tree based on order and lengths of padded data\n",
    "# # Take union of all shifted trees\n",
    "# # Only plot the points that exist in the Union_Tree - X (setminus)\n",
    "# # Equivalently use an if statement\n",
    "# ###############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
